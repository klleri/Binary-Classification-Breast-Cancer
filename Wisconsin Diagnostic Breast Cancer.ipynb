{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wisconsin Diagnostic Breast Cancer (WDBC) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objective is to predict whether a diagnostic is showing a malignant or benign breast cancer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset Informations\n",
    "Number of attributes: 32 <br>\n",
    "Number of instances: 569 <br>\n",
    "\n",
    "###### Attribute information: \n",
    "ID | Subjective Feature <br>\n",
    "diagnosis | Target Variable <br>\n",
    "radius | Objective Feature <br>\n",
    "texture | Objective Feature <br>\n",
    "perimeter | Objective Feature<br>\n",
    "area | Objective Feature<br>\n",
    "smoothness | Objective Feature <br>\n",
    "compactness | Objective Feature <br>\n",
    "concavity | Objective Feature  <br>\n",
    "concave points | Objective Feature  <br>\n",
    "symmetry | Objective Feature <br>\n",
    "fractal dimension | Objective Feature <br>\n",
    "\n",
    "The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data analysis and manipulation tool\n",
    "import pandas as pd\n",
    "#LabelEncoder used to convert categorical Values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Separating Training and Test database\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#all Keras functions has been used to construct neural network\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also can find this repository in : https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use .read_csv not necessary is needed an extension .csv file, but a file with comma-separated-values(csv)\n",
    "rawData = pd.read_csv(\"wdbc.data\")\n",
    "\n",
    "# .head we can see the stutury of our database\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave_points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave_points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave_points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# .info show us if there is any missing attribute values\n",
    "rawData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
      "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
      "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
      "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
      "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
      "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
      "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
      "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
      "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
      "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
      "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
      "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
      "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
      "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
      "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
      "\n",
      "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count   569.000000        569.000000         569.000000       569.000000   \n",
      "mean    880.583128          0.132369           0.254265         0.272188   \n",
      "std     569.356993          0.022832           0.157336         0.208624   \n",
      "min     185.200000          0.071170           0.027290         0.000000   \n",
      "25%     515.300000          0.116600           0.147200         0.114500   \n",
      "50%     686.500000          0.131300           0.211900         0.226700   \n",
      "75%    1084.000000          0.146000           0.339100         0.382900   \n",
      "max    4254.000000          0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "count            569.000000      569.000000               569.000000  \n",
      "mean               0.114606        0.290076                 0.083946  \n",
      "std                0.065732        0.061867                 0.018061  \n",
      "min                0.000000        0.156500                 0.055040  \n",
      "25%                0.064930        0.250400                 0.071460  \n",
      "50%                0.099930        0.282200                 0.080040  \n",
      "75%                0.161400        0.317900                 0.092080  \n",
      "max                0.291000        0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# This step is really important, because this step shows the state of our database, so we can find nonsense values analysing it\n",
    "print(rawData.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step is separating predictors from target, to do this we can use .loc(to use name of the columns) or .iloc (to use the number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors used all Objective Features \n",
    "predictors = rawData.loc[:, 'radius_mean':'fractal_dimension_worst'].values\n",
    "\n",
    "# Target used the only one column, diagnosis \n",
    "target  = rawData.loc[:, 'diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in Target are categorical Values, so they need be converted in numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "target = labelencoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aren't using a big data base, so we just use 25% of the base to test our algorithm, if we was using a big data base, we could just use 10% to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorsTraining, predictorsTest, targetTraining, targetTest = train_test_split(predictors, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential = it’s a linear stack of layers, that can easily create the model by passing a list of layer instances to the constructor. <br>\n",
    "Dense = is a fully connected layer.\n",
    "\n",
    "###### units\n",
    "We need to test the network to discovery the best number of units in each layer, but to initialize a neural network we can use this formula: (input_dim + exit_units) /2\n",
    "\n",
    "###### activation \n",
    "relu<br>\n",
    "The vanishing gradient problem: the gradients of some activation functions becoming increasingly smaller as the number of hidden layers increases. This is problematic because the parameters in the neural network won't be tuned effectively.\n",
    "Since the ReLU has a range of [0, $\\infty$[, gradients won't diminish.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetwork = Sequential()\n",
    "neuralNetwork.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'random_uniform', input_dim = 30))\n",
    "neuralNetwork.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'random_uniform'))\n",
    "neuralNetwork.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'random_uniform'))\n",
    "neuralNetwork.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer and the loss are two arguments that are required if you want to compile the model. Some of the most popular optimization algorithms used are the Stochastic Gradient Descent (SGD), ADAM and RMSprop. Depending on whichever algorithm you choose, you’ll need to tune certain parameters, such as learning rate or momentum. The choice for a loss function depends on the task that you have at hand: for example, for a regression problem, you’ll usually use the Mean Squared Error (MSE). As you see in this example, you used binary_crossentropy for the binary classification problem of determining whether a cancer is malignant or benign. Lastly, with multi-class classification, you’ll make use of categorical_crossentropy.\n",
    "\n",
    "##### Adam Optmizier\n",
    "Calculates adaptive learning rates for each parameter. First computes exponentially weighted average of:\n",
    "a)past gradients\n",
    "b)past square gradients\n",
    "This gives us the mean, and variance of the gradients. These averages have a bias towards 0, so after the bias is corrected, the parameters are updated.\n",
    "\n",
    "##### Binary Crossentropy\n",
    "Cross entropy is calculated by finding the predicted probability, the probability of classification being correct based on given data. <br> \n",
    "loss = -(ylog(p)+(1-y)log(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr = 0.001, decay = 0.0001, clipvalue = 0.5)\n",
    "neuralNetwork.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size defines the number of samples that will be propagated through the network and de epochs how many times this will be processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 0s 667us/step - loss: 0.6876 - binary_accuracy: 0.4320\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 620us/step - loss: 0.6174 - binary_accuracy: 0.6817\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 651us/step - loss: 0.4545 - binary_accuracy: 0.8828\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.3678 - binary_accuracy: 0.8628\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.2607 - binary_accuracy: 0.9164\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.3261 - binary_accuracy: 0.8865\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 608us/step - loss: 0.2813 - binary_accuracy: 0.8931\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2278 - binary_accuracy: 0.9228\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 684us/step - loss: 0.1904 - binary_accuracy: 0.9575\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.2560 - binary_accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.2317 - binary_accuracy: 0.9139\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.2209 - binary_accuracy: 0.9404\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 565us/step - loss: 0.5214 - binary_accuracy: 0.8359\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.3362 - binary_accuracy: 0.8894\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2995 - binary_accuracy: 0.8678\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.2172 - binary_accuracy: 0.9267\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2620 - binary_accuracy: 0.9109\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.3656 - binary_accuracy: 0.8809\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.2293 - binary_accuracy: 0.9047\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 831us/step - loss: 0.2857 - binary_accuracy: 0.9142\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 713us/step - loss: 0.2433 - binary_accuracy: 0.9276\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.2264 - binary_accuracy: 0.9215\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 715us/step - loss: 0.2114 - binary_accuracy: 0.9178\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.3525 - binary_accuracy: 0.8822\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.2372 - binary_accuracy: 0.9165\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2422 - binary_accuracy: 0.9060\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2541 - binary_accuracy: 0.9239\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 600us/step - loss: 0.4215 - binary_accuracy: 0.8730\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2868 - binary_accuracy: 0.8985\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2497 - binary_accuracy: 0.9146\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2691 - binary_accuracy: 0.9097\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2111 - binary_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.1835 - binary_accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2011 - binary_accuracy: 0.9107\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2063 - binary_accuracy: 0.9196\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2574 - binary_accuracy: 0.9058\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.2517 - binary_accuracy: 0.8956\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 831us/step - loss: 0.1842 - binary_accuracy: 0.9374\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.2912 - binary_accuracy: 0.9058\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.3876 - binary_accuracy: 0.8763\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.2882 - binary_accuracy: 0.8917\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.3392 - binary_accuracy: 0.8955\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.1654 - binary_accuracy: 0.9371\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2636 - binary_accuracy: 0.9047\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2391 - binary_accuracy: 0.9186\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 566us/step - loss: 0.2515 - binary_accuracy: 0.9124\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.3079 - binary_accuracy: 0.8955\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2101 - binary_accuracy: 0.9208\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2407 - binary_accuracy: 0.9072\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.1842 - binary_accuracy: 0.9216\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.1770 - binary_accuracy: 0.9357\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.2102 - binary_accuracy: 0.9363\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2458 - binary_accuracy: 0.9163\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2417 - binary_accuracy: 0.9278\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2773 - binary_accuracy: 0.9154\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2298 - binary_accuracy: 0.9190\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 593us/step - loss: 0.2698 - binary_accuracy: 0.9162\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 593us/step - loss: 0.1621 - binary_accuracy: 0.9323\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2394 - binary_accuracy: 0.9271\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2419 - binary_accuracy: 0.9139\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2784 - binary_accuracy: 0.9075\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.3446 - binary_accuracy: 0.8943\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 569us/step - loss: 0.1798 - binary_accuracy: 0.9493\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 499us/step - loss: 0.1998 - binary_accuracy: 0.9278\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2179 - binary_accuracy: 0.9209\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2676 - binary_accuracy: 0.9078\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2329 - binary_accuracy: 0.9168\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.2220 - binary_accuracy: 0.9207\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.1928 - binary_accuracy: 0.9343\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2389 - binary_accuracy: 0.9136\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.1857 - binary_accuracy: 0.9242\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2280 - binary_accuracy: 0.9265\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2289 - binary_accuracy: 0.9383\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2705 - binary_accuracy: 0.9033\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2041 - binary_accuracy: 0.9374\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 522us/step - loss: 0.2606 - binary_accuracy: 0.9150\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.3080 - binary_accuracy: 0.9052\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2510 - binary_accuracy: 0.9134\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2683 - binary_accuracy: 0.9269\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2887 - binary_accuracy: 0.9072\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2006 - binary_accuracy: 0.9229\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.1954 - binary_accuracy: 0.9447\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.1966 - binary_accuracy: 0.9347\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.1804 - binary_accuracy: 0.9354\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2973 - binary_accuracy: 0.9142\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2438 - binary_accuracy: 0.9406\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 594us/step - loss: 0.2473 - binary_accuracy: 0.9037\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2553 - binary_accuracy: 0.9108\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2684 - binary_accuracy: 0.9271\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2337 - binary_accuracy: 0.9186\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2615 - binary_accuracy: 0.9062\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2538 - binary_accuracy: 0.9045\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.3072 - binary_accuracy: 0.9088\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.2425 - binary_accuracy: 0.9319\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.3123 - binary_accuracy: 0.8930\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 571us/step - loss: 0.2430 - binary_accuracy: 0.9281\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 570us/step - loss: 0.2684 - binary_accuracy: 0.9317\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.3060 - binary_accuracy: 0.9121\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 543us/step - loss: 0.2358 - binary_accuracy: 0.9329\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.2049 - binary_accuracy: 0.9409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b319228490>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralNetwork.fit(predictorsTraining, targetTraining, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the results, we can see where our network is doing bad precisions to improve it. A good way to see it, is using confusion matrix, that we can see when the neural network is forecasting a malignant or benign cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92  1]\n",
      " [ 7 43]]\n"
     ]
    }
   ],
   "source": [
    "forecasts = neuralNetwork.predict(predictorsTest)\n",
    "forecasts = (forecasts > 0.5)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precision = accuracy_score(targetTest, forecasts)\n",
    "matriz = confusion_matrix(targetTest, forecasts)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first diagonal its the right aswers, malignant x malignant benign x benign and the second diagonal are the wrong answers, malignant x benign and benign x malignant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
